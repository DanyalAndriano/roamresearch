{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mittens simulations (section 2.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'Nick Dingwall and Christopher Potts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "from mittens import Mittens\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.style.use('mittens.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_count_matrix(n_words):\n",
    "    \"\"\"Returns a symmetric matrix where the entries are drawn from an\n",
    "    exponential distribution. The goal is to provide some structure\n",
    "    for GloVe to learn even with small vocabularies.\n",
    "    \"\"\"\n",
    "    base = np.random.exponential(3.0, size=(n_words, n_words)) / 2    \n",
    "    return np.floor(base + base.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_embedding_lookup(embedding_dim, vocab, percentage_embedded=0.5):\n",
    "    \"\"\"Returns a dict from `percentage_embedded` of the words in \n",
    "    `vocab` to random embeddings with dimension `embedding_dim`.\n",
    "    We seek to make these representations look as much as possible\n",
    "    like the ones we create when initializing GloVe parameters.\n",
    "    \"\"\"\n",
    "    n_words = len(vocab)\n",
    "    val = np.sqrt(6.0 / (n_words + embedding_dim)) * 2.0\n",
    "    embed_size = int(n_words * percentage_embedded)\n",
    "    return {w: np.random.uniform(-val, val, size=embedding_dim)\n",
    "            for w in random.sample(vocab, embed_size)}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_test(mittens, G, embedding_dict, verbose=False):        \n",
    "    dists = defaultdict(list)\n",
    "    warm_start = mittens.G_start\n",
    "    warm_orig = mittens.sess.run(mittens.original_embedding)\n",
    "    for i in range(G.shape[0]):        \n",
    "        if \"w_{}\".format(i) in embedding_dict:\n",
    "            init = warm_orig[i]\n",
    "            key = 'warm'\n",
    "        else:\n",
    "            init = warm_start[i]\n",
    "            key = 'no warm'\n",
    "        dist = euclidean(init, G[i]) \n",
    "        dists[key].append(dist)                    \n",
    "    warm_mean = np.mean(dists['warm'])    \n",
    "    no_warm_mean = np.mean(dists['no warm'])    \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation test for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simulations(n_trials=5, n_words=500, embedding_dim=50, max_iter=1000, \n",
    "        mus=[0.001, 0.1, 0.5, 0, 1, 5, 10]):\n",
    "    \"\"\"Runs the simulations described in the paper. For `n_trials`, we\n",
    "    \n",
    "    * Generate a random count matrix\n",
    "    * Generate initial embeddings for half the vocabulary.\n",
    "    * For each of the specified `mus`:\n",
    "        * Run Mittens at `mu` for `max_iter` times.\n",
    "        * Assess the expected GloVe correlation between counts and\n",
    "          representation dot products.\n",
    "        * Get the mean distance from each vector to its initial\n",
    "          embedding, with the expectation that Mittens will keep\n",
    "          the learned embeddings closer on average, as governed\n",
    "          by `mu`.\n",
    "        \n",
    "    The return value is a `pd.DataFrame` containing all the values\n",
    "    we need for the plots.\n",
    "    \n",
    "    \"\"\"    \n",
    "    data = []\n",
    "    vocab = ['w_{}'.format(i) for i in range(n_words)]\n",
    "    for trial in range(1, n_trials+1):\n",
    "        X = get_random_count_matrix(n_words)            \n",
    "        embedding_dict = get_random_embedding_lookup(embedding_dim, vocab)  \n",
    "        for mu in mus:                      \n",
    "            mittens = Mittens(n=embedding_dim, max_iter=max_iter, mittens=mu)\n",
    "            G = mittens.fit(X, vocab=vocab, initial_embedding_dict=embedding_dict)            \n",
    "            correlations = utils.correlation_test(X, G)\n",
    "            dists = distance_test(mittens, G, embedding_dict)                        \n",
    "            d = {\n",
    "                'trial': trial, \n",
    "                'mu': mu, \n",
    "                'corr_log_cooccur': correlations['log_cooccur'], \n",
    "                'corr_prob': correlations['prob'], \n",
    "                'corr_pmi': correlations['pmi'], \n",
    "                'warm_distance_mean': np.mean(dists['warm']),\n",
    "                'no_warm_distance_mean': np.mean(dists['no warm'])\n",
    "            }\n",
    "            data.append(d)\n",
    "    return pd.DataFrame(data)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df = simulations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Correlation plot (figure 1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_corr_stats(vals, correlation_value='corr_prob'):\n",
    "    \"\"\"Helper function for `correlation_plot`: returns the mean\n",
    "    and lower confidence interval bound in the format that \n",
    "    pandas expects.\n",
    "    \"\"\"\n",
    "    mu = vals[correlation_value].mean() \n",
    "    lower, upper = utils.get_ci(vals[correlation_value])\n",
    "    return pd.DataFrame([{'mean': mu, 'err': mu-lower}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlation_plot(data_df, correlation_value='corr_prob'):\n",
    "    \"\"\"Produces Figure 1a.\"\"\"\n",
    "    corr_df = data_df.groupby('mu').apply(lambda x: get_corr_stats(x, correlation_value))\n",
    "    corr_df = corr_df.reset_index().sort_values(\"mu\", ascending=False)\n",
    "    ax = corr_df.plot.barh(\n",
    "        x='mu', y='mean', xerr='err', \n",
    "        legend=False, color=['gray'], \n",
    "        lw=1, edgecolor='black')\n",
    "    ax.set_xlabel(r'Mean Pearson $\\rho$')\n",
    "    ax.set_ylabel(r'$\\mu$')\n",
    "    plt.savefig(\"correlations-{}.pdf\".format(correlation_value), layout='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlation_plot(data_df, correlation_value='corr_log_cooccur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlation_plot(data_df, correlation_value='corr_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlation_plot(data_df, correlation_value='corr_pmi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distances plot (figure 1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dist_stats(x):  \n",
    "    \"\"\"Helper function for `distance_plot`: returns the means\n",
    "    and lower confidence interval bounds in the format that \n",
    "    pandas expects.\n",
    "    \"\"\"\n",
    "    warm_mu = x['warm_distance_mean'].mean()\n",
    "    warm_err = warm_mu-utils.get_ci(x['warm_distance_mean'])[0]\n",
    "    no_warm_mu = x['no_warm_distance_mean'].mean()\n",
    "    no_warm_err = no_warm_mu-utils.get_ci(x['no_warm_distance_mean'])[0]\n",
    "    return pd.DataFrame([{\n",
    "        'pretrained initialization': warm_mu,\n",
    "        'pretrained initialization_ci': warm_err,\n",
    "        'random initialization': no_warm_mu,\n",
    "        'random initialization_ci': no_warm_err}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_plot(data_df):\n",
    "    \"\"\"Produces Figure 1b.\"\"\"\n",
    "    cols = ['pretrained initialization', 'random initialization']\n",
    "    dist_df = data_df.groupby('mu').apply(get_dist_stats)\n",
    "    dist_df = dist_df.reset_index(level=1).sort_index(ascending=False)\n",
    "    err_df = dist_df[['pretrained initialization_ci', 'random initialization_ci']]\n",
    "    err_df.columns = cols\n",
    "    data_df = dist_df[['pretrained initialization', 'random initialization']]    \n",
    "    ax = data_df.plot.barh(\n",
    "        color=['#0499CC', '#FFFFFF'], \n",
    "        xerr=err_df, lw=1, edgecolor='black')\n",
    "    ax.set_xlabel('Mean distance from initialization')\n",
    "    ax.set_ylabel(r'$\\mu$')\n",
    "    legend = plt.legend(loc='center left', bbox_to_anchor=(0.4, 1.15))    \n",
    "    plt.savefig(\"distances.pdf\", \n",
    "                bbox_extra_artists=(legend,), \n",
    "                bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance_plot(data_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
