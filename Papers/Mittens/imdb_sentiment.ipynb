{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'Nick Dingwall and Christopher Potts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IMDB dataset is here:\n",
    "\n",
    "http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "\n",
    "This should be unpacked and placed in this directory.\n",
    "\n",
    "Stanford's publicly-released GloVe vectors are also required and should also be unpacked into this directory:\n",
    "\n",
    "http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bootstrap\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from mittens.tf_mittens import Mittens, GloVe\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report, accuracy_score, \n",
    "    confusion_matrix, f1_score)\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count matrix from the unsupervised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_texts(dirname):\n",
    "    \"\"\"Loads the raw 'unsup' texts and puts them into a `pd.Series`.\"\"\"\n",
    "    texts = []\n",
    "    for filename in glob.glob(os.path.join(dirname, \"*.txt\")):\n",
    "        with open(filename) as f:\n",
    "            texts.append(f.read())\n",
    "    return pd.Series(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = load_texts(os.path.join('aclImdb', 'train', 'unsup'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = utils.build_weighted_matrix(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Build a word x word matrix with dimensionality {:,} x {:,}\".format(*X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_labeled_data(dirname):\n",
    "    \"\"\"Tokenize the train or test portion of the data, as given by \n",
    "    `dirname`. Returns a list of `(tokens, cls)` pairs where `tokens` \n",
    "    is a list of str and `cls` is a string.    \n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for cls in ['neg', 'pos']:\n",
    "        for filename in glob.glob(os.path.join(dirname, cls, \"*.txt\")):\n",
    "            with open(filename) as f:\n",
    "                tokens = utils.basic_tokenizer(f.read())\n",
    "                data.append((tokens, cls))\n",
    "    return data                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = load_labeled_data(os.path.join('aclImdb', 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = {w for tokens, _ in train_data for w in tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = load_labeled_data(os.path.join('aclImdb', 'test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GLOVE_LOOKUP = utils.create_glove_lookup('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize(data, lookup):\n",
    "    \"\"\"Featurizing `data` according to `lookup`, a map from\n",
    "    strings to vectors. The return values are `np.arrays`,\n",
    "    with each examples in `X` represented by the sum of \n",
    "    the vectors for the words it contains.    \n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for tokens, label in data:            \n",
    "        x = np.array([_get_rep(w, lookup) for w in tokens])\n",
    "        x = x.sum(axis=0)\n",
    "        X.append(x)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def _get_rep(w, lookup):\n",
    "    \"\"\"Try to look up `w` in `lookup`, and fall back to GloVe\n",
    "    for out of vocabulary words. If a word is also not in \n",
    "    GloVe, then its representation is random.\n",
    "    \"\"\"\n",
    "    if w in lookup:\n",
    "        return lookup[w]\n",
    "    else:\n",
    "        return GLOVE_LOOKUP[w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experiment(train_data, test_data, lookup, label, trial_num):\n",
    "    \"\"\"Run a standard IMDB movie review experiment using `lookup` as \n",
    "    the basis for representing examples. The results are pickled to a \n",
    "    file called \"results/imdb_{label}.pickle\"    \n",
    "    \"\"\"        \n",
    "    output_filename = \"results/imdb_{}_trial{}.pickle\".format(label, trial_num)            \n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    # Model:\n",
    "    cv = GridSearchCV(\n",
    "        RandomForestClassifier(), \n",
    "        param_grid={\n",
    "            'n_estimators': [100, 200, 300, 400, 500],\n",
    "            'max_features': ['sqrt', 'log2'],\n",
    "            'max_depth': [3, 5, None]}, \n",
    "        refit=True, \n",
    "        n_jobs=-1)  \n",
    "    \n",
    "    # Split:\n",
    "    X_train, y_train = featurize(train_data, lookup)\n",
    "    X_test, y_test = featurize(test_data, lookup)\n",
    "    \n",
    "    # Fit with best estimator and predict:\n",
    "    cv.fit(X_train, y_train)\n",
    "    predictions = cv.predict(X_test) \n",
    "    \n",
    "    # CV info:\n",
    "    results['cv_results'] = cv.cv_results_\n",
    "    results['best_params'] = cv.best_params_\n",
    "    results['best_score'] = cv.best_score_\n",
    "        \n",
    "    # Test-set scoring:\n",
    "    acc = accuracy_score(y_test, predictions)               \n",
    "    results['accuracy'] = acc\n",
    "    results['confusion_matrix'] = confusion_matrix(y_test, predictions)\n",
    "    results['f1'] = f1_score(y_test, predictions, average=None)\n",
    "    results['f1_macro'] = f1_score(y_test, predictions, average='macro')\n",
    "    results['f1_micro'] = f1_score(y_test, predictions, average='micro')\n",
    "    \n",
    "    # Summary report:\n",
    "    print(\"Accuracy: {0:0.04%}\".format(acc))\n",
    "    print(\"Best params:\", cv.best_params_)\n",
    "          \n",
    "    # Storage:\n",
    "    with open(output_filename, 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_trials = 5\n",
    "\n",
    "max_iter = 50000\n",
    "\n",
    "embedding_dim = 50\n",
    "\n",
    "eta = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for trial_num in range(1, n_trials+1):\n",
    "    random_lookup = create_random_lookup(vocab)\n",
    "    experiment(train_data, test_data, random_lookup, 'random', trial_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment(train_data, test_data, GLOVE_LOOKUP, 'external_glove', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for trial_num in range(1, n_trials+1):    \n",
    "    glove = GloVe(max_iter=max_iter, n=embedding_dim, eta=eta)\n",
    "    G = glove.fit(X.values)\n",
    "    G = pd.DataFrame(G, index=X.index)\n",
    "    G.to_csv(\"imdb_glove_embedding_{}.csv.gzip\".format(trial_num), compression='gzip')\n",
    "    imdb_glove_lookup = utils.create_lookup(G)    \n",
    "    experiment(train_data, test_data, imdb_glove_lookup, 'imdb_glove', trial_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mittens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for trial_num in range(1, n_trials+1):      \n",
    "    mittens = Mittens(max_iter=max_iter, n=embedding_dim, eta=eta, mittens=1.0)\n",
    "    G_mittens = mittens.fit(\n",
    "        X.values, \n",
    "        vocab=list(X.index), \n",
    "        initial_embedding_dict=GLOVE_LOOKUP)\n",
    "    G_mittens = pd.DataFrame(G_mittens, index=X.index)\n",
    "    G.to_csv(\"imdb_mittens_embedding_{}.csv.gzip\".format(trial_num), compression='gzip')\n",
    "    mittens_lookup = utils.create_lookup(G_mittens)    \n",
    "    experiment(train_data, test_data, mittens_lookup, 'mittens', trial_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert pickled results to JSON for portability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_all(dirname):\n",
    "    for filename in glob.glob(os.path.join(dirname, \"*.pickle\")):\n",
    "        data = convert(filename)\n",
    "\n",
    "def convert(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    data = type_convert(data)\n",
    "        \n",
    "    output_filename = filename.replace(\".pickle\", \".json\")\n",
    "    with open(output_filename, 'wt') as f:\n",
    "        json.dump(data, f, indent=4, sort_keys=True)\n",
    "    return data\n",
    "\n",
    "def type_convert(d):\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            v = type_convert(v)\n",
    "        if type(v) == type(np.array([1])):\n",
    "            v = v.tolist()\n",
    "        elif isinstance(v, np.ma.core.MaskedArray):\n",
    "            v = {'data': v.data.tolist(), 'mask': v.mask.tolist()}\n",
    "        d[k] = v\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_all(\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ci(vals):\n",
    "    \"\"\"Bootstrapped 95% confidence intervals.\"\"\"\n",
    "    return bootstrap.ci(vals, method='bca')\n",
    "\n",
    "def analyze_model(model_name):\n",
    "    data = []\n",
    "    base = \"imdb_{}_trial*.json\".format(model_name)\n",
    "    filenames = glob.glob(os.path.join(\"results\", base))\n",
    "    for filename in filenames:\n",
    "        with open(filename, 'rt') as f:\n",
    "            results = json.load(f)\n",
    "            data.append(results['accuracy'])\n",
    "    data = np.array(data)\n",
    "    mu = \"${:0.02%}$\".format(data.mean())\n",
    "    if len(data) > 1:\n",
    "        ci = \"${:0.02%}-{:0.02%}$\".format(*get_ci(data))\n",
    "    else:\n",
    "        ci = \"$-$\"\n",
    "    print(\"{:>20} & {} & {}\".format(model_name, mu, ci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model_name in ('random', 'external_glove', 'imdb_glove', 'mittens'):\n",
    "    analyze_model(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
